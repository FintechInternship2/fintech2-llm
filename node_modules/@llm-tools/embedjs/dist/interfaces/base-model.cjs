"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.BaseModel = void 0;
const debug_1 = __importDefault(require("debug"));
const uuid_1 = require("uuid");
class BaseModel {
    static setDefaultTemperature(temperature) {
        BaseModel.defaultTemperature = temperature;
    }
    static setConversations(conversations) {
        BaseModel.conversations = conversations;
    }
    constructor(temperature) {
        Object.defineProperty(this, "baseDebug", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: (0, debug_1.default)('embedjs:model:BaseModel')
        });
        Object.defineProperty(this, "_temperature", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this._temperature = temperature;
    }
    get temperature() {
        return this._temperature ?? BaseModel.defaultTemperature;
    }
    async init() { }
    async query(system, userQuery, supportingContext, conversationId = 'default') {
        const conversation = await BaseModel.conversations.getConversation(conversationId);
        this.baseDebug(`${conversation.entries.length} history entries found for conversationId '${conversationId}'`);
        // Add user query to history
        await BaseModel.conversations.addEntryToConversation(conversationId, {
            id: (0, uuid_1.v4)(),
            timestamp: new Date(),
            actor: 'HUMAN',
            content: userQuery,
        });
        // Run LLM implementation in subclass
        const response = await this.runQuery(system, userQuery, supportingContext, conversation.entries.slice(0, -1));
        const uniqueSources = this.extractUniqueSources(supportingContext);
        const newEntry = {
            id: (0, uuid_1.v4)(),
            timestamp: new Date(),
            content: response.result,
            actor: 'AI',
            sources: uniqueSources,
        };
        // Add AI response to history
        await BaseModel.conversations.addEntryToConversation(conversationId, newEntry);
        return {
            ...newEntry,
            tokenUse: {
                inputTokens: response.tokenUse?.inputTokens ?? 'UNKNOWN',
                outputTokens: response.tokenUse?.outputTokens ?? 'UNKNOWN',
            },
        };
    }
    extractUniqueSources(supportingContext) {
        const uniqueSources = new Map(); // Use a Map to track unique sources by URL
        supportingContext.forEach((item) => {
            const { metadata } = item;
            if (metadata && metadata.source) {
                // Use the source URL as the key to ensure uniqueness
                if (!uniqueSources.has(metadata.source)) {
                    uniqueSources.set(metadata.source, {
                        source: metadata.source,
                        loaderId: metadata.uniqueLoaderId, // Assuming this field always exists
                    });
                }
            }
        });
        // Convert the values of the Map to an array
        return Array.from(uniqueSources.values());
    }
}
exports.BaseModel = BaseModel;
